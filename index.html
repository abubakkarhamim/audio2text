<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Gemini Audio Transcriber</title>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css">
  <style>
    body { 
      background: #f0f2f5;
      display: flex;
      justify-content: center;
      align-items: center;
      min-height: 100vh;
      font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif;
    }
    .container { 
      max-width: 500px;
      width: 100%;
    }
    .card { 
      padding: 30px;
      border-radius: 20px; 
      box-shadow: 0 8px 32px rgba(0,0,0,0.1); 
      background: #fff;
      border: none;
    }
    #recordButton {
      width: 80px;
      height: 80px;
      border-radius: 50%;
      background-color: #dc3545;
      border: none;
      display: flex;
      justify-content: center;
      align-items: center;
      cursor: pointer;
      transition: all 0.3s ease;
      box-shadow: 0 4px 10px rgba(220, 53, 69, 0.4);
    }
    #recordButton:hover {
      transform: scale(1.05);
    }
    #recordButton.recording {
      background-color: #ff4d4d;
      animation: pulse 1.5s infinite;
    }
    #recordIcon {
      width: 40px;
      height: 40px;
      color: white;
    }
    @keyframes pulse {
      0% { box-shadow: 0 0 0 0 rgba(255, 77, 77, 0.7); }
      70% { box-shadow: 0 0 0 20px rgba(255, 77, 77, 0); }
      100% { box-shadow: 0 0 0 0 rgba(255, 77, 77, 0); }
    }
    #transcription { 
      white-space: pre-wrap; 
      background: #f8f9fa; 
      padding: 20px; 
      border-radius: 12px; 
      min-height: 120px; 
      margin-top: 20px;
      border: 1px solid #e9ecef;
    }
    .recorder-container {
      display: flex;
      flex-direction: column;
      align-items: center;
      margin-bottom: 20px;
    }
    #visualizer {
      width: 100%;
      height: 100px;
      background: #f8f9fa;
      border-radius: 12px;
      margin-bottom: 20px;
      display: none; /* Hidden by default */
    }
  </style>
</head>
<body>
  <div class="container">
    <div class="card">
      <h3 class="mb-4 text-center">ðŸŽ¤ Audio Transcriber</h3>

      <div class="recorder-container">
        <canvas id="visualizer"></canvas>
        <button id="recordButton">
          <svg id="recordIcon" viewBox="0 0 24 24">
            <path fill="currentColor" d="M12,2A3,3 0 0,1 15,5V11A3,3 0 0,1 12,14A3,3 0 0,1 9,11V5A3,3 0 0,1 12,2M19,11C19,14.53 16.39,17.44 13,17.93V21H11V17.93C7.61,17.44 5,14.53 5,11H7A5,5 0 0,0 12,16A5,5 0 0,0 17,11H19Z" />
          </svg>
        </button>
      </div>

      <form id="apiForm">
        <div class="mb-3">
          <label for="apiKey" class="form-label">Gemini API Key</label>
          <div class="input-group">
            <input type="password" class="form-control" id="apiKey" placeholder="Enter your Gemini API key" required>
            <button class="btn btn-outline-secondary" type="button" id="saveApiKey">Save</button>
          </div>
        </div>
        <div class="mb-3">
          <label for="model" class="form-label">Model</label>
          <select class="form-select" id="model">
            <option value="gemini-1.5-pro-latest">Gemini 1.5 Pro</option>
            <option value="gemini-2.5-flash">Gemini 2.5 Flash</option>
          </select>
        </div>
        <div class="mb-3">
          <label for="audioFile" class="form-label">Or Upload Audio File</label>
          <input type="file" class="form-control" id="audioFile" accept="audio/*">
        </div>
        <div class="mb-3">
          <label for="prompt" class="form-label">Prompt (optional)</label>
          <input type="text" class="form-control" id="prompt" placeholder="e.g., Transcribe the audio to text. The audio is in English.">
        </div>
        <button type="submit" class="btn btn-primary w-100 mt-3">Transcribe</button>
      </form>

      <h5 class="mt-4">Transcription:</h5>
      <div id="transcription"></div>
    </div>
  </div>

  <script>
    let mediaRecorder;
    let audioChunks = [];
    let audioContext;
    let analyser;
    let visualizerCanvas = document.getElementById("visualizer");
    let visualizerCtx = visualizerCanvas.getContext("2d");
    let animationFrameId;

    document.addEventListener("DOMContentLoaded", () => {
      const savedApiKey = localStorage.getItem("geminiApiKey");
      if (savedApiKey) {
        document.getElementById("apiKey").value = savedApiKey;
      }
    });

    document.getElementById("saveApiKey").addEventListener("click", () => {
      const apiKey = document.getElementById("apiKey").value;
      if (apiKey) {
        localStorage.setItem("geminiApiKey", apiKey);
        alert("API key saved locally.");
      } else {
        alert("Please enter an API key.");
      }
    });

    document.getElementById("recordButton").addEventListener("click", async () => {
      const recordButton = document.getElementById("recordButton");
      if (!mediaRecorder || mediaRecorder.state === "inactive") {
        try {
          let stream = await navigator.mediaDevices.getUserMedia({ audio: true });
          setupVisualizer(stream);
          mediaRecorder = new MediaRecorder(stream);

          mediaRecorder.ondataavailable = event => audioChunks.push(event.data);
          mediaRecorder.onstop = () => {
            const blob = new Blob(audioChunks, { type: "audio/webm" });
            const file = new File([blob], "recording.webm", { type: "audio/webm" });
            const dataTransfer = new DataTransfer();
            dataTransfer.items.add(file);
            document.getElementById("audioFile").files = dataTransfer.files;

            audioChunks = [];
            recordButton.classList.remove("recording");
            visualizerCanvas.style.display = "none";
            if (audioContext) audioContext.close();
            if(animationFrameId) cancelAnimationFrame(animationFrameId);
          };

          mediaRecorder.start();
          recordButton.classList.add("recording");
          visualizerCanvas.style.display = "block";
        } catch (err) {
          console.error("Error starting recording:", err);
          alert("Could not start recording. Please make sure you have a microphone connected and have granted permission.");
        }
      } else {
        mediaRecorder.stop();
      }
    });

    function setupVisualizer(stream) {
      audioContext = new (window.AudioContext || window.webkitAudioContext)();
      analyser = audioContext.createAnalyser();
      const source = audioContext.createMediaStreamSource(stream);
      source.connect(analyser);
      analyser.fftSize = 2048;
      const bufferLength = analyser.frequencyBinCount;
      const dataArray = new Uint8Array(bufferLength);

      function draw() {
        animationFrameId = requestAnimationFrame(draw);
        analyser.getByteTimeDomainData(dataArray);

        visualizerCtx.fillStyle = "#f8f9fa";
        visualizerCtx.fillRect(0, 0, visualizerCanvas.width, visualizerCanvas.height);
        visualizerCtx.lineWidth = 2;
        visualizerCtx.strokeStyle = "#dc3545";
        visualizerCtx.beginPath();

        const sliceWidth = visualizerCanvas.width * 1.0 / bufferLength;
        let x = 0;

        for (let i = 0; i < bufferLength; i++) {
          const v = dataArray[i] / 128.0;
          const y = v * visualizerCanvas.height / 2;

          if (i === 0) {
            visualizerCtx.moveTo(x, y);
          } else {
            visualizerCtx.lineTo(x, y);
          }

          x += sliceWidth;
        }

        visualizerCtx.lineTo(visualizerCanvas.width, visualizerCanvas.height / 2);
        visualizerCtx.stroke();
      }

      draw();
    }

    document.getElementById("apiForm").addEventListener("submit", async e => {
      e.preventDefault();
      const apiKey = document.getElementById("apiKey").value;
      const model = document.getElementById("model").value;
      const file = document.getElementById("audioFile").files[0];
      const prompt = document.getElementById("prompt").value || "Transcribe the audio to text.";

      if (!apiKey || !file) {
        document.getElementById("transcription").textContent = "Please provide an API key and audio file.";
        return;
      }

      const reader = new FileReader();
      reader.onload = async function () {
        const base64Data = btoa(
          new Uint8Array(reader.result)
            .reduce((data, byte) => data + String.fromCharCode(byte), '')
        );

        try {
          const res = await fetch(`https://generativelanguage.googleapis.com/v1beta/models/${model}:generateContent?key=${apiKey}`, {
            method: "POST",
            headers: { "Content-Type": "application/json" },
            body: JSON.stringify({
              contents: [{
                role: "user",
                parts: [
                  { text: prompt },
                  {
                    inline_data: {
                      mime_type: file.type,
                      data: base64Data
                    }
                  }
                ]
              }]
            })
          });

          const data = await res.json();
          if (res.status === 429) {
            document.getElementById("transcription").textContent = "Error: You have exceeded your API quota. Please check your plan and billing details.";
          } else if (data.candidates && data.candidates[0].content) {
            document.getElementById("transcription").textContent =
              data.candidates[0].content.parts[0].text;
          } else {
            console.error("Error with API response:", data);
            document.getElementById("transcription").textContent = "Error: Could not transcribe audio. The API response was: " + JSON.stringify(data);
          }
        } catch (err) {
          console.error("Error during transcription:", err);
          document.getElementById("transcription").textContent = "Error: Could not connect to the transcription service.";
        }
      };

      reader.readAsArrayBuffer(file);
    });
  </script>
</body>
</html>
